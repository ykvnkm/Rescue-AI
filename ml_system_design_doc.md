# Дизайн ML системы — Обнаружение людей на видеопотоке с БПЛА (MVP)

## 1. Цели и предпосылки

### 1.1. Зачем идём в разработку продукта?

#### Бизнес-цель
Сократить время обнаружения человека оператором и снизить объём ручного просмотра при мониторинге видеопотока с БПЛА в ходе поисково-спасательных операций за счёт автоматических подсказок (детекций человека), чтобы оператор реагировал на события, а не выполнял сплошной визуальный поиск по кадрам.

#### Почему станет лучше, чем сейчас, от использования ML
- Вместо механического мониторинга потока внимание оператора освобождается для принятия решения и планирования дальнейших действий.
- Повышается оперативность реакции наземной поисковой группы.
- При том же составе смены возможно обработать больший объём данных или выполнить больше вылетов без резкого роста нагрузки на команду.
- Упрощается отчётность и дальнейший разбор полётов, так как результаты работы системы фиксируются в едином виде.

#### Критерии успеха итерации

##### 1) Ускорение обнаружения — снижение времени до первого подтверждения цели оператором (TtFC)
Определение:

```tex
TtFC = t_{\text{confirm}} - t_{\text{start}}
```

где:
- `t_confirm` — момент, когда оператор впервые подтверждает «это человек»;
- `t_start` — начало мониторинга.

Критерий успеха — относительное улучшение TtFC по сравнению с ручным мониторингом:

```tex
\Delta TtFC =
\frac{\operatorname{median}(TtFC_{\text{hand}}) - \operatorname{median}(TtFC_{\text{model}})}
     {\operatorname{median}(TtFC_{\text{hand}})}
```

где:
- `TtFC_hand` — TtFC при ручном мониторинге;
- `TtFC_model` — TtFC при использовании ML.

Порог:


```tex
\Delta TtFC \geq 0.25
```

Улучшение считается устойчивым, если на более чем 50% пилотных миссий TtFC при использовании ML даёт выигрыш по сравнению с ручным мониторингом не менее 25%.

---

##### 2) Снижение трудозатрат — сокращение активного времени взаимодействия оператора (ΔT_review)
Определения:
- `T_hand` — время мониторинга в ручном режиме;
- `T_model` — активное время в ML-режиме (проверка алертов).

Критерий успеха:

```tex
\Delta T_{\text{review}} = \frac{T_{\text{hand}} - T_{\text{model}}}{T_{\text{hand}}}
```

Порог:

```tex
\Delta T_{\text{review}} \geq 0.5
```

Улучшение считается устойчивым, если на более чем 50% пилотных миссий (например, за 10 минут облёта) активное время проверки в ML-режиме составляет около 3 минут после автоматической обработки, по сравнению с 10-минутным ручным мониторингом, при этом улучшение не достигается ценой пропуска целей (см. пункт 3).

---

##### 3) Полезность подсказок — полнота по эпизодам (Recall_event)
Важно, чтобы система хотя бы раз подсветила человека, когда он реально находится в кадре, чтобы помочь оператору быстро отреагировать. Иначе теряется смысл использования ML во время мониторинга.

Качество метрики оценивается на уровне эпизодов присутствия человека в кадре. Эпизод — интервал времени, в котором человек реально виден на видео. Пусть в пилотном наборе есть `K` эпизодов появления человека, и для каждого известен интервал времени:

```tex
[s_k, e_k], \quad k = 1,\dots,K
```

где:
- `s_k` — начало эпизода;
- `e_k` — конец эпизода;
- `k` — индекс эпизода.

Пусть модель выдаёт алерты в моменты времени `t ∈ A`, где `A` — множество временных меток алертов. Эпизод `k` считается найденным, если хотя бы один алерт попал в его интервал (с допуском `τ` секунд):

```tex
\text{found}_k =
\begin{cases}
1, & \exists t \in A: \ s_k - \tau \le t \le e_k + \tau \\
0, & \text{иначе}
\end{cases}
```

Критерий успеха — полнота по эпизодам:

```tex
Recall_{\text{event}} = \frac{1}{K} \sum_{k=1}^{K} \text{found}_k
```

Порог:

```tex
Recall_event \geq 0.9
```

---

##### 4) Контроль ложных тревог — ограничение частоты ложных алертов (FP/h)
Система ограничивает количество ложных алертов, чтобы не повышать нагрузку на оператора из-за отвлечения на проверки подозрительных сигналов.

Пороговые значения:
- Дежурный режим (людей чаще всего нет): не более 7 FP в час (≈ 0.12 FP/min).
- Режим активного поиска (важнее не пропустить): не более 12 FP в час (≈ 0.20 FP/min).


---

### 1.2. Бизнес-требования и ограничения

#### Бизнес-требования
Система должна поддерживать применение БПЛА в поисково-спасательных операциях в режиме мониторинга видеопотока и помогать оператору за счёт автоматических подсказок о вероятном присутствии человека. Результат работы — снижение времени до первого подтверждения цели и снижение объёма ручной проверки при сохранении высокой вероятности не пропустить человека.

По функционалу решение предполагает:
- получение видеопотока с БПЛА или видеозаписи миссии;
- формирование подсказок оператору в виде событий/алертов с детекцией человека (класс `Person`) и временными метками;
- минимально достаточную визуализацию для принятия решения (кадр + bbox + таймкод);
- фиксацию показателей в отчёте по миссии (срабатывания, базовые сводные показатели), пригодном для последующего разбора полёта.

#### Бизнес-ограничения
- Подсказки должны приходить достаточно быстро, чтобы их можно было использовать по ходу миссии.
- Количество алертов должно быть ограничено, чтобы оператор мог продолжать управление миссией.
- Пилот предполагает работу без облачной инфраструктуры.
- Решение должно работать на коммерчески доступном одноплатном компьютере (ориентиры: Raspberry Pi 4B и Orin Nano).
- Эффект должен подтверждаться на нескольких миссиях, а не на одном демонстрационном примере.

#### Что ожидаем от конкретной итерации
MVP для пилота, который можно использовать в операторском контуре без ручной настройки в полевых условиях: единый сценарий запуска, понятный интерфейс отображения подсказок и фиксируемый результат работы в виде отчёта и логов. Система позволяет воспроизводимо провести испытания на нескольких миссиях и собрать данные, достаточные для расчёта метрик из пункта 1.1 и принятия решения о дальнейшем развитии и продуктивизации решения.

##### Описание бизнес-процесса пилота
**MVP** — рабочий прототип для демонстрации: система принимает видео/поток, детектит `Person`, показывает bbox/алерты и базовый контекст. На этапе MVP эффект по бизнес-метрикам измеряется вручную: оператор смотрит видео без подсказок и по таймкоду фиксирует момент первого подтверждения цели и оценивает время активной проверки (вручную в таблице).

**Пилот** — проверка бизнес-эффекта в операторском процессе по регламенту: один и тот же материал проходит два сопоставимых прогона (ручной режим vs режим с ML). Система автоматически логирует алерты и действия оператора (подтверждения/отклонения), формирует отчёт и рассчитывает метрики из пункта 1.1. По отчёту принимается решение о дальнейших итерациях.

#### Критерии успеха пилота
Успешный пилот — это пилот, в котором есть измеримое улучшение по бизнес-метрикам процесса (ускорение первого подтверждения и снижение ручной проверки) относительно ручного режима. Улучшение не достигается ценой пропусков цели, а частота ложных тревог остаётся управляемой для оператора. Система работает в реальном или около-реальном времени без критичных задержек и без опоры на облако, формирует понятные отчёты для разбора.

#### Возможные пути развития после пилота
- улучшение качества детекции;
- добавление двух режимов чувствительности для realtime- и постобработки;
- оптимизация под целевое железо;
- при возможности — интеграция с внешними системами и датчиками на дроне.

### 1.3. Что входит в скоуп проекта/итерации, что не входит

#### На закрытие каких БТ подписываемся в данной итерации
- Детекция класса `Person` на видеопотоке/кадрах с управляемой настройкой порога уверенности и выдачей результата в UI.
- Формирование подсказок в виде алертов с временными метками.
- Воспроизводимая оценка качества и производительности на наборе миссий для принятия решения по следующей итерации.

#### Что не будет закрыто
- интеграция с дополнительными датчиками на борту, в том числе ночной поиск с использованием тепловизионных данных;
- автономное принятие решений уровня полётного контроллера;
- гарантированная точность геопривязки к координатам на карте без внешних источников.

#### Описание результата с точки зрения качества кода и воспроизводимости решения
Воспроизводимое пилотное end-to-end решение в виде репозитория с фиксированными зависимостями, понятными точками запуска и конфигурациями; воспроизводимый пайплайн обучения/оценки и единый формат отчётов; зафиксированные версии датасета/разметки, весов модели и параметров инференса. Воспроизводимость подразумевает, что на одном и том же наборе пилотных миссий при одинаковых конфигурациях получаются сопоставимые метрики эффекта и отчёт пилота, а также сохраняются логи алертов и решений оператора.

**Описание планируемого технического долга:** полный набор оптимизаций под устройства типа Raspberry Pi и Orin Nano (квантизация, прореживание, оптимизации на уровне рантайма); авторизация и разделение прав на сервисе.

### 1.4. Предпосылки решения
Модель работает в режиме обработки видеопотока: горизонт принятия решения — текущий кадр/короткий интервал времени. Продуктовый результат и бизнес-метрики считаются на уровне алертов, потому что именно так измеряется нагрузка на оператора и полезность подсказок в процессе миссии.

- Данные: для обучения и проверки используются размеченные данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологических конкурсов (около 60 000 изображений людей в природной среде; различные регионы/сезоны/погода).
- Предполагается, что человек в кадре может быть малым объектом на сложном фоне (лес/поле), возможны частичные перекрытия, различия по высоте полёта, освещению и погоде.
- Предполагается локальный контур обработки без облачной инфраструктуры; вычисления должны быть возможны на edge-устройстве, сопоставимом с Raspberry Pi и Orin Nano, и применимыми в полевых условиях.
- Стек: дообученный детектор на базе YOLO-подхода с последующей постобработкой (ROI-каскад, трекинг, фильтры временной устойчивости), сервисный слой на FastAPI.

---

## 2. Методология (Data Scientist)

### 2.1. Постановка задачи
С технической точки зрения решается задача **детекции** объекта класса `Person` (человек) на кадрах c дрона (на продуктовом слое кадры агрегируются в алерты)

| Бизнес-метрика                                      | ML-/системная метрика                                                         |
| --------------------------------------------------- | ----------------------------------------------------------------------------- |
| `TtFC` — время до первого подтверждения             | p95 inference latency + end-to-end latency контура алертов                    |
| `ΔT_review` — снижение ручной проверки              | FP/min (по алертам), настройка порога confidence, правила агрегации алертов   |
| `Recall_event` — полезность подсказок (по эпизодам) | Recall@IoU≥0.5 на bbox/кадрах + устойчивость во времени (агрегация в события) |
| Ограничение ложных тревог                           | Precision / FPR, FP/min (после агрегации)                                     |

`Recall_event` считается по эпизодам (достаточно хотя бы одного алерта, попавшего во временной интервал присутствия человека). Это измеряет пользу оператору, потому что оператор работает не с каждым кадром, а с интервалами времени.

---

### 2.3. Этапы решения задачи (Data Scientist)

#### 2.3.1. Этап 1 — подготовка данных
Для обучения и валидации используются данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологического конкурса «Экстренный поиск НТИ» с применением БПЛА. Сущность наблюдения для модели — изображение с дрона, целевая переменная — bbox человека в формате YOLO.

Таблица источников данных:

| Название данных                   | Есть ли данные / источник | Требуемый ресурс | Проверено ли качество |
| --------------------------------- | ------------------------- | ---------------- | --------------------- |
| Кадры (images)                    | Dataset_Human_Rescue      | DS/ML            | +                     |
| Аннотации bbox (labels YOLO .txt) | Dataset_Human_Rescue      | DS/ML            | +                     |

Фактический сплит по количеству изображений:

| split | images |
|---|---:|
| train | 8484 |
| val | 1000 |
| test | 50538 |

Результаты автоматических проверок аннотаций по сплитам:

| split | images_total | images_without_labels | bboxes_total | zero_wh | outside | too_small | unknown_class | pct_images_without_labels |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| test | 50538 | 20531 | 41481 | 0 | 0 | 21808 | 0 | 0.406249 |
| train | 8484 | 4398 | 6827 | 0 | 0 | 6807 | 0 | 0.518388 |
| val | 1000 | 294 | 1763 | 0 | 0 | 1671 | 0 | 0.294000 |

- **images_without_labels** - кадры без bbox класса Person. Доля негативных кадров высокая (в трейне 52%), в аннотациях это отражено в виде пустых txt-файлов к кадрам без детекций. При оценке нужно внимательно смотреть FP/min и поведение порога
	
- **zero_wh** - боксы с нулевой/отрицательной шириной/высотой (ошибка разметки). Ошибок разметки нет
	
- **outside** - координаты выходят за интервал [0,1] (ошибка нормализации/границы). Нормализация корректная
	
- **unknown_class** — class_id не входит в словарь классов. Здесь всего один класс (Person, 0), неизвестных классов нет
	
- **too_small** - bbox с площадью < 0.1% кадра. Большая доля маленьких объектов - нужно разобраться, объясняется ли это тем, что объект действительно часто очень мал относительно кадра (типичный сценарий съемки с дрона), или является ошибкой разметки. Нужно проверить выборку самых маленьких bbox, удалить или переразметить при необходимости; разработать стратегию для малых объектов (повышение разрешения, мульти-скейл, ROI-каскад).

##### Статистика bbox (масштаб и плотность)
Сводная статистика по изображениям, где есть хотя бы один bbox:

| split | images_total | bboxes_total | bbox_per_image_mean | width_px_mean | height_px_mean | area_px_p05 | area_px_p50 | area_px_p90 |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| test | 30007 | 41481 | 1.382377 | 82.255399 | 80.735249 | 741.305615 | 6176.994166 | 14009.920306 |
| train | 4086 | 6827 | 0.805045 | 95.589960 | 92.540647 | 857.285302 | 8065.228825 | 14522.247000 |
| val | 706 | 1763 | 2.497167 | 101.683673 | 97.985454 | 2891.199626 | 9050.949807 | 17329.120111 |

Диагностические распределения:

| split | aspect_mean | aspect_q05 | aspect_q95 | center_x_mean | center_x_std | center_y_mean | center_y_std |
|---|---:|---:|---:|---:|---:|---:|---:|
| test | 1.129182 | 0.453703 | 2.116882 | 0.510173 | 0.286799 | 0.503750 | 0.284406 |
| train | 1.139437 | 0.450683 | 2.366991 | 0.503067 | 0.300250 | 0.493794 | 0.280244 |
| val | 1.161277 | 0.476004 | 2.333377 | 0.501427 | 0.196259 | 0.511063 | 0.249590 |

Ключевые выводы:
- **bbox_per_image_mean** — среднее число людей на позитивный кадр (плотность целей). В val оно выше, чем в train/test, значит валидация может давать более оптимистичную картину по recall относительно реального потока. Требуется проверить, нет ли перекоса по сценам.
- **width_px_mean / height_px_mean, area_px_p05/p50/p90** — типичный размер цели в пикселях. В val почти нет крайне маленьких целей (p05 заметно выше), поэтому модель может выглядеть хорошо на val, но деградировать в миссиях/test, где мелких целей больше. Нужно готовить модель к малым объектам через обучение и аугментации.
- **aspect_mean/q05/q95** — соотношение сторон bbox (w/h). В среднем bbox близки к квадрату, но квантили q05/q95 указывают на наличие вытянутых разметок. Перед обучением требуется проверить, являются ли это нормальной вариативностью (ракурсы/частичные видимости) или выбросами/ошибками разметки.
- **center_x_mean / center_y_mean** — среднее положение объектов в кадре (в долях размеров кадра). Значения близки к 0.5: в среднем объекты распределены симметрично по кадру (нет сильного позиционного перекоса).
- **center_x_std / center_y_std** — разброс по позициям. В val он ниже, что может быть ещё одним сигналом перекоса сцен. Нужно проверить, что разбиение делалось по миссиям/сценам без утечки и без отбора «слишком удобных» кадров.

##### Таргет и связь с бизнес-ценностью
**Таргет:** bbox человека в формате YOLO:

```tex
\langle class\_id, x, y, w, h\rangle
```

где `x,y` — центр bbox, `w,h` — ширина/высота; все величины нормированы в долях ширины/высоты изображения.

**Вывод:** в данной задаче приоритет обучения — максимизация полноты (recall) при контроле ложных тревог. В исходном датасете тестовая выборка значительно больше тренировочной, так как тест включает в себя большое количество негативных кадров (без человека), собранных с видеопотока реальной миссии. Эти кадры предназначены для приближенной оценки эксплуатационных метрик и проверки устойчивости всего пайплайна, в то время как управление качеством модели идёт через train/val. При этом нужно подтвердить, что распределение в val репрезентативно относительно test, т.е. ожидаемых миссий.

##### Что нужно сделать перед обучением
1. Зафиксировать конкретные целевые значения каждой ML-метрики, основываясь на значениях соответствующих бизнес-метрик из пункта 1.1.
2. Вручную проверить выборку самых маленьких bbox и принять правило: оставляем (тогда обучаемся под малые объекты) либо чистим (вводим минимальный порог площади/размера и пересохраняем лейблы).
3. **Пересобрать валидационную выборку так, чтобы она отражала наличие очень малых целей и пространственное распределение, близкое к миссиям.**
4. Проверить, что конфиги обучения и оценки используют один и тот же словарь классов (class_id = 0).