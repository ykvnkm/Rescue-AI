# Дизайн ML системы — Обнаружение людей на потоке с БПЛА (MVP)

## 1. Цели и предпосылки

### 1.1. Зачем идём в разработку продукта?

#### Бизнес-цель
Сократить время обнаружения человека оператором и повысить скорость его реакции при мониторинге видеопотока с БПЛА в ходе поисково-спасательных операций за счёт автоматических подсказок (детекций человека), чтобы оператор реагировал на события, а не выполнял сплошной визуальный поиск по кадрам.

#### Почему станет лучше, чем сейчас, от использования ML
- Вместо механического мониторинга потока внимание оператора освобождается для принятия решения и планирования дальнейших действий.
- Повышается оперативность реакции наземной поисковой группы.
- При том же составе смены возможно обработать больший объём данных или выполнить больше вылетов без резкого роста нагрузки на команду.
- Упрощается отчётность и дальнейший разбор полётов, так как результаты работы системы фиксируются в едином виде.

#### Критерии успеха итерации
##### 1) Ускорение обнаружения (снижение времени до подтверждения цели оператором)

Метрика Time-to-First-Confirm (TtFC) - сколько секунд нужно, чтобы заметить цель, когда она уже присутствует:
```math
TtFC = t_{\text{confirm}} - t_{\text{start}}
```
где:
- `t_confirm` — момент, когда оператор впервые подтверждает, что видит человека;
- `t_start` — момент, когда человек появляется в кадре.

Критерий успеха — относительное улучшение TtFC по сравнению с ручным мониторингом:

```math
\Delta TtFC =
\frac{\text{median}(TtFC_{\text{hand}}) - \text{median}(TtFC_{\text{model}})}
{\text{median}(TtFC_{\text{hand}})}
```

```math
\Delta TtFC \geq 0.25
```
где:

- `TtFC_hand` — TtFC при ручном мониторинге;
- `TtFC_model` — TtFC при использовании ML.

При ручном мониторинге значение `TtFC_hand` = **8,69 секунд**. Таким образом, улучшение считается устойчивым, если на более чем 50% пилотных миссий:

```math
TtFC \leq 6.52\ \text{с}
```

---
##### 2) Полезность подсказок (полнота по эпизодам)

Важно, чтобы система хотя бы раз подсветила человека, когда он реально находится в кадре, чтобы помочь оператору быстро отреагировать. Иначе теряется смысл использования ML во время мониторинга.

Качество метрики оценивается на уровне эпизодов присутствия человека в кадре. 

**Эпизод** — это интервал времени, когда человек реально присутствует в кадре (GT).

Пусть в пилотном наборе есть `K` эпизодов появления человека, и для каждого известен интервал времени:

```math
[s_k, e_k], \quad k = 1,\dots,K
```
где:
- `s_k` — начало эпизода;
- `e_k` — конец эпизода;
- `k` — индекс эпизода.

**Алерт** — это событие, которое генерирует система, чтобы привлечь внимание оператора. Алерт считается по результатам агрегации детекций (bbox + порог уверенности + подтверждение на нескольких кадрах)

Пусть модель выдаёт алерты в моменты времени `t ∈ A`, где `A` — множество временных меток алертов. Эпизод `k` считается найденным, если хотя бы один алерт попал в его интервал (с допуском `τ` секунд):

```math
\text{found}_k =
\begin{cases}
1, & \exists t \in A: s_k - \tau \le t \le e_k + \tau \\
0, & \text{иначе}
\end{cases}
```

Критерий успеха — полнота по эпизодам:
```math
Recall_{\text{event}} = \frac{1}{K} \sum_{k=1}^{K} \text{found}_k
```

```math
Recall_{\text{event}} \geq 0.9
```
---
##### 4) Контроль ложных тревог

Система ограничивает количество ложных алертов, чтобы не повышать нагрузку на оператора из-за отвлечения на проверки подозрительных сигналов. Пороговое значение— 2 ложных алерта на 5 минут миссии, следовательно в минуту:
```math
\text{FP}/\text{мин} \leq 0.4
```

---
### 1.2. Бизнес-требования и ограничения
#### Бизнес-требования
Система должна поддерживать применение БПЛА в поисково-спасательных операциях в режиме мониторинга видеопотока и помогать оператору за счёт автоматических подсказок о вероятном присутствии человека. Результат работы — снижение времени до первого подтверждения цели при сохранении высокой вероятности не пропустить человека.

По функционалу решение предполагает:
- получение видеопотока с БПЛА или видеозаписи миссии;
- формирование подсказок оператору в виде событий/алертов с детекцией человека (класс `Person`) и временными метками;
- минимально достаточную визуализацию для принятия решения (кадр + bbox + таймкод);
- фиксацию показателей в отчёте по миссии (срабатывания, базовые сводные показатели), пригодном для последующего разбора полёта.

#### Бизнес-ограничения
- Подсказки должны приходить достаточно быстро, чтобы их можно было использовать по ходу миссии.
- Количество алертов должно быть ограничено, чтобы оператор мог продолжать управление миссией.
- Пилот предполагает работу без облачной инфраструктуры.
- Эффект должен подтверждаться на нескольких миссиях, а не на одном демонстрационном примере.

#### Что ожидаем от конкретной итерации
MVP для пилота, который можно использовать в операторском контуре без ручной настройки в полевых условиях: единый сценарий запуска, понятный интерфейс отображения подсказок и фиксируемый результат работы в виде отчёта и логов. Система позволяет воспроизводимо провести испытания на нескольких миссиях и собрать данные, достаточные для расчёта метрик из пункта 1.1 и принятия решения о дальнейшем развитии и продуктивизации решения.

#### Описание бизнес-процесса пилота
Пилот проводится на наборе миссий в виде последовательных потоков кадров фиксированной длительности с временными метками и  GT-разметкой присутствия человека. Для обеспечения сопоставимости результатов перед пилотом фиксируются версия модели, параметры инференса и правила формирования алертов:

- порог уверенности `conf_thr = 0.2` 
- размер окна `W = 1 сек`
- количество срабатываний в окне `k = 3` 
- минимальный интервал между алертами `cooldown = 5 сек` 
- `τ_gap_end = 1 сек` (если цель пропала дольше, считаем алерт завершенным)

 Каждый алерт имеет временную метку и используется как продуктовая подсказка о вероятном присутствии человека.

Качество пилота оценивается по метрикам, рассчитываемым по результатам прогона каждой миссии и затем агрегируемым по всему набору миссий. Метрика `TtFC` определяется как разница между началом **первого GT-эпизода** появления человека и временем **первого алерта**, который пересёкся с этим эпизодом (с допуском ±τ секунд).

Например, человек присутствует в двух эпизодах (`s - start`, `e - end`, `t - timestamp` считаются относительно начала миссии):

- Эпизод 1: `s1 = 10.0 c`, `e1 = 18.0 c` 
- Эпизод 2: `s2 = 40.0 c`, `e2 = 46.0 c`

Система присылает алерты с метками времени:
- `t = 8.5 c`
- `t = 12.3 c`
- `t = 41.0 c`

Пусть допуск `τ = 1.0 c`. Тогда допустимый интервал для эпизода 1 — `[9.0 c, 19.0 c]`

В этот интервал попал только алерт `12.3 c`, так как  `8.5 c` <  `9.0 c`, а `41.0 c` относится к другому эпизоду. Оператору в среднем нужно `2.5 c` для принятия решения и подтверждения после алерта, тогда:

```math
TtFC = t_{\text{confirm}} - t_{\text{start}} = t - s_{1} + 2.5 = 12.3 - 10.0 + 2.5 = 4.8\ \text{с}
```

То есть система среагировала через 2.3 секунды после начала появления человека в кадре, а общее время до подтверждения составило 4.8 секунды.

Метрика `Recall_event`рассчитывается как доля найденных эпизодов от общего числа эталонных эпизодов по миссии. Для контроля нагрузки фиксируется количество ложных тревог `FP/мин ≤ 0.4`

По завершении пилота система формирует отчёт, включающий: список алертов с временными метками и оценкой корректности относительно эпизодов, рассчитанные значения `TtFC`, `Recall_event` и показателя ложных тревог по каждой миссии, а также сводную агрегацию по всему пилотному набору. Полученные результаты используются для принятия решения о готовности текущей конфигурации алертинга и порогов к дальнейшей итерации или внедрению, а также для выбора направлений улучшений (изменение порога, правил агрегации, дообучение модели на характерных сценариях пропусков/ложных срабатываний).

#### Критерии успеха пилота
```math
\Delta TtFC \geq 0.25
```

```math
Recall_{\text{event}} \geq 0.9
```

```math
\text{FP}/\text{мин} \leq 0.4
```

Успешный пилот — это пилот, в котором на >50% миссий есть измеримое улучшение по бизнес-метрикам процесса относительно ручного режима. Улучшение не достигается ценой пропусков цели, а частота ложных тревог остаётся управляемой для оператора. Система работает без критичных задержек и без опоры на облако, формирует понятные отчёты для разбора.

#### Возможные пути развития после пилота
- улучшение качества детекции;
- калибровка режимов чувствительности для разных условий окружающей среды;
- оптимизация под целевое железо (коммерчески доступные одноплатные компьютеры типа RaspberryPi 4B и Orin Nano);
- при возможности — интеграция с внешними системами и датчиками на дроне.

---
### 1.3. Что входит в скоуп проекта/итерации, что не входит

#### На закрытие каких БТ подписываемся в данной итерации
- Детекция класса `Person` на видеопотоке/кадрах с управляемой настройкой порога уверенности и выдачей результата в UI.
- Формирование подсказок в виде алертов с временными метками.
- Воспроизводимая оценка качества и производительности на наборе миссий для принятия решения по следующей итерации.

#### Что не будет закрыто
- интеграция с дополнительными датчиками на борту, в том числе ночной поиск с использованием тепловизионных данных;
- автономное принятие решений уровня полётного контроллера;
- гарантированная точность геопривязки к координатам на карте без внешних источников.

#### Описание результата с точки зрения качества кода и воспроизводимости решения
Воспроизводимое пилотное end-to-end решение в виде репозитория с фиксированными зависимостями, понятными точками запуска и конфигурациями; воспроизводимый пайплайн обучения/оценки и единый формат отчётов; зафиксированные версии датасета/разметки, весов модели и параметров инференса. Воспроизводимость подразумевает, что на одном и том же наборе пилотных миссий при одинаковых конфигурациях получаются сопоставимые метрики эффекта и отчёт пилота, а также сохраняются логи алертов и решений оператора.

#### Описание планируемого технического долга
Полный набор оптимизаций под устройства типа Raspberry Pi и Orin Nano (квантизация, прореживание, оптимизации на уровне рантайма); авторизация и разделение прав на сервисе.

---
### 1.4. Предпосылки решения

Модель работает в режиме обработки видеопотока: горизонт принятия решения — текущий кадр/короткий интервал времени. Продуктовый результат и бизнес-метрики считаются на уровне алертов, потому что именно так измеряется нагрузка на оператора и полезность подсказок в процессе миссии.

- Данные: для обучения и проверки используются размеченные данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологических конкурсов (около 60 000 изображений людей в природной среде; различные регионы/сезоны/погода).
- Предполагается, что человек в кадре может быть малым объектом на сложном фоне (лес/поле), возможны частичные перекрытия, различия по высоте полёта, освещению и погоде.
- Предполагается локальный контур обработки без облачной инфраструктуры;
- Стек: дообученный детектор на базе YOLO-подхода с последующей постобработкой (ROI-каскад, трекинг, фильтры временной устойчивости), сервисный слой на FastAPI.

---

## 2. Методология (Data Scientist)

### 2.1. Постановка задачи
С технической точки зрения решается задача **детекции** объекта класса `Person` (человек) на кадрах c дрона (на продуктовом слое кадры агрегируются в алерты)

| Бизнес-метрика | ML-/системная метрика                                   |
| -------------- | ------------------------------------------------------- |
| `TtFC`         | p95 inference latency, Recall@IoU≥0.5                   |
| `Recall_event` | Recall@IoU≥0.5 на bbox/кадрах + устойчивость во времени |
| `FP/мин`       | Precision / FPR                                         |

---

### 2.3. Этапы решения задачи (Data Scientist)

#### 2.3.1. Этап 1 — подготовка данных
Для обучения и валидации используются данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологического конкурса «Экстренный поиск НТИ» с применением БПЛА. Сущность наблюдения для модели — изображение с дрона, целевая переменная — bbox человека в формате YOLO.

Таблица источников данных:

| Название данных                   | Есть ли данные / источник | Требуемый ресурс | Проверено ли качество |
| --------------------------------- | ------------------------- | ---------------- | --------------------- |
| Кадры (images)                    | Dataset_Human_Rescue      | DS/ML            | +                     |
| Аннотации bbox (labels YOLO .txt) | Dataset_Human_Rescue      | DS/ML            | +                     |

Фактический сплит по количеству изображений:

| split | images |
|---|---:|
| train | 8484 |
| val | 1000 |
| test | 50538 |

Результаты автоматических проверок аннотаций по сплитам:

| split | images_total | images_without_labels | bboxes_total | zero_wh | outside | too_small | unknown_class | pct_images_without_labels |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| test | 50538 | 20531 | 41481 | 0 | 0 | 21808 | 0 | 0.406249 |
| train | 8484 | 4398 | 6827 | 0 | 0 | 6807 | 0 | 0.518388 |
| val | 1000 | 294 | 1763 | 0 | 0 | 1671 | 0 | 0.294000 |

- **images_without_labels** - кадры без bbox класса Person. Доля негативных кадров высокая (в трейне 52%), в аннотациях это отражено в виде пустых txt-файлов к кадрам без детекций. При оценке нужно внимательно смотреть FP/min и поведение порога
	
- **zero_wh** - боксы с нулевой/отрицательной шириной/высотой (ошибка разметки). Ошибок разметки нет
	
- **outside** - координаты выходят за интервал [0,1] (ошибка нормализации/границы). Нормализация корректная
	
- **unknown_class** — class_id не входит в словарь классов. Здесь всего один класс (Person, 0), неизвестных классов нет
	
- **too_small** - bbox с площадью < 0.1% кадра. Большая доля маленьких объектов - нужно разобраться, объясняется ли это тем, что объект действительно часто очень мал относительно кадра (типичный сценарий съемки с дрона), или является ошибкой разметки. Нужно проверить выборку самых маленьких bbox, удалить или переразметить при необходимости; разработать стратегию для малых объектов (повышение разрешения, мульти-скейл, ROI-каскад).

Сводная статистика по изображениям, где есть хотя бы один bbox:

| split | images_total | bboxes_total | bbox_per_image_mean | width_px_mean | height_px_mean | area_px_p05 | area_px_p50 | area_px_p90 |
|---|---:|---:|---:|---:|---:|---:|---:|---:|
| test | 30007 | 41481 | 1.382377 | 82.255399 | 80.735249 | 741.305615 | 6176.994166 | 14009.920306 |
| train | 4086 | 6827 | 0.805045 | 95.589960 | 92.540647 | 857.285302 | 8065.228825 | 14522.247000 |
| val | 706 | 1763 | 2.497167 | 101.683673 | 97.985454 | 2891.199626 | 9050.949807 | 17329.120111 |

| split | aspect_mean | aspect_q05 | aspect_q95 | center_x_mean | center_x_std | center_y_mean | center_y_std |
|---|---:|---:|---:|---:|---:|---:|---:|
| test | 1.129182 | 0.453703 | 2.116882 | 0.510173 | 0.286799 | 0.503750 | 0.284406 |
| train | 1.139437 | 0.450683 | 2.366991 | 0.503067 | 0.300250 | 0.493794 | 0.280244 |
| val | 1.161277 | 0.476004 | 2.333377 | 0.501427 | 0.196259 | 0.511063 | 0.249590 |

- **bbox_per_image_mean** — среднее число людей на позитивный кадр (плотность целей). В val оно выше, чем в train/test, значит валидация может давать более оптимистичную картину по recall относительно реального потока. Требуется проверить, нет ли перекоса по сценам.
- **width_px_mean / height_px_mean, area_px_p05/p50/p90** — типичный размер цели в пикселях. В val почти нет крайне маленьких целей (p05 заметно выше), поэтому модель может выглядеть хорошо на val, но деградировать в миссиях/test, где мелких целей больше. Нужно готовить модель к малым объектам через обучение и аугментации.
- **aspect_mean/q05/q95** — соотношение сторон bbox (w/h). В среднем bbox близки к квадрату, но квантили q05/q95 указывают на наличие вытянутых разметок. Перед обучением требуется проверить, являются ли это нормальной вариативностью (ракурсы/частичные видимости) или выбросами/ошибками разметки.
- **center_x_mean / center_y_mean** — среднее положение объектов в кадре (в долях размеров кадра). Значения близки к 0.5: в среднем объекты распределены симметрично по кадру (нет сильного позиционного перекоса).
- **center_x_std / center_y_std** — разброс по позициям. В val он ниже, что может быть ещё одним сигналом перекоса сцен. Нужно проверить, что разбиение делалось по миссиям/сценам без утечки и без отбора «слишком удобных» кадров.

**Таргет:** bbox человека в формате YOLO:

```math
\langle class\_id, x, y, w, h\rangle
```

где `x,y` — центр bbox, `w,h` — ширина/высота; все величины нормированы в долях ширины/высоты изображения.

**Вывод:** в данной задаче приоритет обучения — максимизация полноты (recall) при контроле ложных тревог. В исходном датасете тестовая выборка значительно больше тренировочной, так как тест включает в себя большое количество негативных кадров (без человека), собранных с видеопотока реальной миссии. Эти кадры предназначены для приближенной оценки эксплуатационных метрик и проверки устойчивости всего пайплайна, в то время как управление качеством модели идёт через train/val. При этом нужно подтвердить, что распределение в val репрезентативно относительно test, т.е. ожидаемых миссий.

##### Что нужно сделать перед обучением
1. Зафиксировать конкретные целевые значения каждой ML-метрики, основываясь на значениях соответствующих бизнес-метрик из пункта 1.1.
2. Вручную проверить выборку самых маленьких bbox и принять правило: оставляем (тогда обучаемся под малые объекты) либо чистим (вводим минимальный порог площади/размера и пересохраняем лейблы).
3. **Пересобрать валидационную выборку так, чтобы она отражала наличие очень малых целей и пространственное распределение, близкое к миссиям.**
4. Проверить, что конфиги обучения и оценки используют один и тот же словарь классов (class_id = 0).
