## Дизайн ML системы - Обнаружение людей на потоке с БПЛА - MVP
---

### 1. Цели и предпосылки 
#### 1.1. Зачем идем в разработку продукта?  

##### Бизнес-цель
Сократить время обнаружения человека оператором и снизить объём ручного просмотра при мониторинге видеопотока с БПЛА в ходе поисково-спасательных операций за счёт автоматических подсказок (детекций человека), чтобы оператор реагировал на события, а не выполнял сплошной визуальный поиск по кадрам

##### Почему станет лучше, чем сейчас, от использования ML
Значительная часть ПСО с применением БПЛА до сих пор опирается на ручной визуальный контроль видеопотока. Оператор или в реальном времени отслеживает изображение с камеры во время облёта, или просматривает записанные материалы после миссии. Качество обнаружения и скорость реакции в обоих случаях зависят от человеческого фактора: утомляемости, внимания, опыта конкретного специалиста и длительности мониторинга. При высокой динамике миссии и большом объеме видеоданных увеличивается время и повышается риск пропуска цели.

Внедрение ML-модели меняет непрерывный визуальный поиск на проверку событий, благодаря чему:
- вместо механического мониторинга потока, внимание оператора освобождается для принятия решения и планирования дальнейших действий
- повышается оперативность реакции наземной поисковой группы
- миссия становится более управляемой, так как оператор получает не сырое видео, а события, которые ему нужно проверить
- при том же составе смены возможно обработать больший объем данных или сделать больше вылетов без резкого роста нагрузки на команду
- упрощается отчетность и дальнейший разбор полетов, так как результаты работы системы фиксируются в едином виде
  
##### Критерии успеха итерации

1. Ускорение обнаружения - модель сокращает время до первого подтверждения цели оператором **TtFC** (Time-to-First-Confirm):

$$  
TtFC = t_{\text{confirm}} - t_{\text{start}},  
$$

- $t_{\text{confirm}}$ - момент, когда оператор впервые подтверждает «это человек»,
- $t_{\text{start}}$ - начало мониторинга.

Критерий успеха - относительное улучшение TtFC по сравнению с ручным мониторингом:

$$  
\Delta TtFC = \frac{\operatorname{median}(TtFC_{\text{hand}}) - \operatorname{median}(TtFC_{\text{model}})}{\operatorname{median}(TtFC_{\text{hand}})},
$$

- $TtFC_{\text{hand}}$ - метрика TtFC при ручном мониторинге,
- $TtFC_{\text{model}}$ - метрика TtFC при использовании ML.

Улучшение считается устойчивым, если на > 50% пилотных миссий $TtFC_{\text{model}} < TtFC_{\text{hand}}$ 

---

2. Снижение трудозатрат - модель сокращает общее время активного взаимодействия оператора с системой, благодаря чему можно совершить больше миссий тем же составом смены:

- $T_{\text{hand}}$ - время мониторинга в ручном режиме,
- $T_{\text{model}}$ - время, потраченное в ML-режиме (проверка алертов)

Критерий успеха:

$$  
\Delta T_{\text{review}} = \frac{T_{\text{hand}} - T_{\text{model}}}{T_{\text{hand}}}  
$$

Улучшение считается устойчивым, если на > 50% пилотных миссий $i$ выполняется $T_{\text{model, i}} < T_{\text{hand, i}}$ , при этом улучшение не достигается ценой пропуска целей (см. п. 3)

---

3. Полезность подсказок - важно, чтобы модель хотя бы раз подсветила человека, когда он реально находится в кадре, чтобы помочь оператору быстро отреагировать. В ином случае теряется весь смысл использования ML во время мониторинга. 

Качество метрики оценивается на уровне эпизодов присутствия человека в кадре. Эпизод - **это интервал времени, в котором человек реально виден на видео**. Пусть в пилотном наборе есть K эпизодов появления человека, и для каждого известен интервал времени:

$$  
[s_k, e_k], \quad k = 1,\dots,K,   
$$
- $s_{\text{k}}$ - начало интервала,
- $e_{\text{k}}$ - конец интервала,
- $k$ - эпизод

Пусть модель выдает алерты в моменты времени $t \in A$, где $A$ — множество всех временных меток алертов. **Эпизод $k$ считается найденным**, если хотя бы один алерт попал в его интервал (с погрешностью $\tau$ секунд):

$$
\text{found}_k =  
\begin{cases}  
1, & \exists t \in A:  s_k - \tau \le t \le e_k + \tau \\  
0, & \text{иначе}  
\end{cases}  
$$

Критерий успеха - наивысшая полнота по эпизодам:

$$
Recall_{\text{event}} = \frac{1}{K}\sum_{k=1}^{K}\text{found}_k  
$$

---

4. Контроль ложных тревог - система ограничивает количество ложных алертов, чтобы не повышать нагрузку на оператора в части отвлечения на проверку подозрительных сигналов. Количество ложных алертов (человек обнаруживается 1 секунду подряд) не должно превышать 1 в дежурном режиме, когда людей чаще всего нет, и 2-3 в режиме активного поиска, когда важнее не пропустить.

---

5. Оперативность - модель обеспечивает пропускную способность кадров, приемлемую для того, чтобы использовать ее в ходе миссии, а не после: FPS ≥ 8

---

#### 1.2. Бизнес-требования и ограничения  

##### Бизнес-требования
Система должна поддерживать применение БПЛА в поисково-спасательных операциях в режиме мониторинга видеопотока и помогать оператору за счет автоматических подсказок о вероятном присутствии человека. Результат работы - снижение времени до первого подтверждения цели и снижение объема ручной проверки при сохранении высокой вероятности не пропустить человека.

По функционалу, решение предполагает:
- получение видеопотока с БПЛА или видеозаписи миссии 
- формирование подсказок оператору в виде событий/алертов с детекцией человека (класс Person) с временными метками
- минимально достаточную визуализацию для принятия решения (кадр + боксы + метки времени)
- фиксацию показателей в отчете по миссии (срабатывания, базовые сводные показатели), пригодном для последующего разбора полета

##### Бизнес-ограничения
- Подсказки должны приходить достаточно быстро, чтобы их можно было использовать по ходу миссии
- Количество алертов должно быть ограничено, чтобы оператор мог продолжать управление миссией
- Пилот предполагает работу без облачной инфраструктуры
- Решение должно работать на коммерчески доступном одноплатном компьютере. Ориентиры - RaspberryPi 4B и Orin Nano
- Эффект должен подтверждаться на нескольких миссиях, а не на одном демонстрационном примере

##### Что ожидаем от конкретной итерации
MVP для пилота, который можно использовать в операторском контуре без ручной настройки в полевых условиях. То есть единый сценарий запуска, понятный интерфейс отображения подсказок и фиксируемый результат работы в виде отчета и логов. Система позволяет воспроизводимо провести испытания на нескольких миссиях и собрать данные, достаточные для расчета метрик из п. 1.1 и принятия решения о дальнейшем развитии и продуктивизации решения.

##### Описание бизнес-процесса пилота
Пилот - два сопоставимых прогона на одном и том же материале (типовом сценарии ПСО с известными эпизодами присутствия человека):

1. Ручной мониторинг - оператор выполняет мониторинг без подсказок и фиксирует момент первого подтверждения цели и затраченное активное время проверки
    
2. Мониторинг с ML-моделью: тот же материал проходит через систему, оператор получает алерты (детекции), подтверждает/отклоняет их, фиксирует временные метки событий и момент первого подтверждения
    
По итогам прогонов рассчитываются метрики эффекта итерации, перечисленные в п. 1.1, формируется отчет по полету.

##### Критерии успеха пилота
Успешный пилот - это пилот, в котором есть измеримое улучшение по бизнес-метрикам процесса (ускорение первого подтверждения и снижение ручной проверки) относительно ручного режима, это улучшение не достигается ценой пропусков цели, b частота ложных тревог управляемая для оператора. Система работает в реальном или около-реальном времени без критичных задержек без опоры на облако, формирует понятные отчеты для разбора

**Возможные пути развития после пилота:**
- улучшение качества детекции 
- добавление двух режимов чувствительности для реалтайм- и постобработки
- оптимизация под целевое железо
- при возможности - интеграция с внешними системами и датчиками на дроне

#### 1.3. Что входит в скоуп проекта/итерации, что не входит   

##### На закрытие каких БТ подписываемся в данной итерации
- Детекция класса person на видеопотоке/кадрах с управляемой настройкой порога уверенности и выдачей результата в UI
- Формирование подсказок в виде алертов с временными метками
- Воспроизводимая оценка качества и производительности на наборе миссий для принятия решения по следующей итерации
##### Что не будет закрыто
- интеграция с дополнительными датчиками на борту, в том числе ночной поиск с использованием тепловизионных данных
- автономное принятие решений уровня полетного контроллера
- гарантированная точность геопривязки к координатам на карте без внешних источников
##### Описание результата с точки зрения качества кода и воспроизводимости решения
Воспроизводимое пилотное end-to-end решение в виде репозитория с фиксированными зависимостями, понятными точками запуска и конфигурациями; воспроизводимый пайплайн обучения/оценки и единый формат отчетов; зафиксированные версии датасета/разметки, весов модели и параметров инференса. Воспроизводимость подразумевает, что на одном и том же наборе пилотных миссий при одинаковых конфигурациях получаются сопоставимые метрики эффекта и отчет пилота, а также сохраняются логи алертов и решений оператора. 

**Описание планируемого технического долга:** Полный набор оптимизаций под устройства типа RaspberryPi и Orin Nano (квантизация, прореживание, оптимизации на уровне рантайма); авторизация и разделение прав на сервисе

---

#### 1.4. Предпосылки решения  
Модель работает в режиме обработки видеопотока: горизонт принятия решения - текущий кадр/короткий интервал времени. Продуктовый результат и бизнес-метрики считаются на уровне алертов, потому что именно так измеряется нагрузка на оператора и полезность подсказок в процессе миссии.

- Данные: для обучения и проверки используются размеченные данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологических конкурсов (60000  изображений людей в природной среде, различные регионы/сезоны/погода)
- Предполагается, что человек в кадре может быть малым объектом на сложном фоне (лес/поле), возможны частичные перекрытия, различия по высоте полета, освещению и погоде
- Предполагается локальный контур обработки без облачной инфраструктуры; вычисления должны быть возможны на edge-устройстве, сопоставимом с RaspberryPi и Orin Nano, и применимыми в полевых условиях
- Стек: дообученный детектор на базе YOLO-подхода с последующей постобработкой (ROI-каскад, трекинг, фильтры временной устойчивости), сервисный слой на FastAPI

### 2. Методология `Data Scientist`     
#### 2.1. Постановка задачи

С технической точки зрения решаем задачу детекции объекта класса Person (человек) на кадрах

| Бизнес-метрика                                                       | ML-метрика                                                 |
| -------------------------------------------------------------------- | ---------------------------------------------------------- |
| $TtFC$ - время до первого обнаружения                                | p95 inference latency + end-to-end latency контура алертов |
| $\Delta T_{\text{review}}$ - снижение ручной проверки                | FP/min, настройка confidence                               |
| $Recall_{\text{event}}$ - полнота по эпизодам (полезность подсказок) | Recall при IoU≥0.5                                         |
| Ограничение ложных тревог                                            | Precision / FPR, FP/min                                    |
| Пропускная способность                                               | FPS                                                        |


$Recall_{\text{event}}$  считается по эпизодам (хотя бы один алерт попал во временной интервал присутствия человека). Это измеряет **пользу оператору**, потому что оператор работает не с каждым кадром, а с интервалами времени.

---
#### 2.3. Этапы решения задачи `Data Scientist`

#### 2.3.1 Этап 1 — подготовка данных

Для обучения и валидации используются данные, собранные совместно с ДПСО «ЛизаАлерт» в рамках технологического конкурса «Экстренный поиск НТИ» с применением БПЛА. Сущность наблюдения для модели - изображение с дрона, целевая переменная - bbox человека в формате YOLO.

| Название данных                  | Есть ли данные / источник | Требуемый ресурс для получения данных | Проверено ли качество данных |
| -------------------------------- | ------------------------- | ------------------------------------- | ---------------------------- |
| Кадры (images)                   | Dataset_Human_Rescue      | DS/ML                                 | +                            |
| Аннотации bbox (labels YOLO.txt) | Dataset_Human_Rescue      | DS/ML                                 | +                            |

Фактический сплит на train/test/val по количеству изображений:

|split|images|
|:--|--:|
|train|8484|
|val|1000|
|test|50538|

В исходном датасете тестовая выборка значительно больше тренировочной, так как тест включает в себя большое количество неразмеченных изображений, собранных с потока видео и приближенных к реальной миссии, которые предназначены для проверки устойчивости качества уже готовых решений (это было отражено в условиях конкурса).

Практическое следствие для дальнейшей работы:

- **в итерациях обучения** основное управление качеством идёт через train/val (быстрый цикл),
    
- **test** используется как “финальный экзамен” (и/или как большой прогон для оценки устойчивости и FP/min), чтобы не переобучаться на валидацию.
    

Результаты автоматических проверок аннотаций по сплитам:

| split | images_total | images_without_labels | bboxes_total | zero_wh | outside | too_small | unknown_class | pct_images_without_labels |
| :---- | -----------: | --------------------: | -----------: | ------: | ------: | --------: | ------------: | ------------------------: |
| test  |        50538 |                 20531 |        41481 |       0 |       0 |     21808 |             0 |                  0.406249 |
| train |         8484 |                  4398 |         6827 |       0 |       0 |      6807 |             0 |                  0.518388 |
| val   |         1000 |                   294 |         1763 |       0 |       0 |      1671 |             0 |                  0.294000 |

- **images_without_labels** - кадры без bbox класса Person
  Доля негативных кадров высокая (в трейне 52%), в аннотациях это отражено в виде пустых txt-файлов к кадрам без детекций. При оценке нужно внимательно смотреть FP/min и поведение порога
    
- **zero_wh** - боксы с нулевой/отрицательной шириной/высотой (ошибка разметки)
  Ошибок разметки нет
    
- **outside** - координаты выходят за интервал [0,1] (ошибка нормализации/границы)
  Нормализация корректная
    
- **unknown_class** — class_id не входит в словарь классов
  Здесь всего один класс (Person, 0), неизвестных классов нет
    
- **too_small** - bbox с площадью < 0.1% кадра
  Большая доля маленьких объектов - нужно разобраться, объясняется ли это тем, что объект действительно часто очень мал относительно кадра (типичный сценарий съемки с дрона), или является ошибкой разметки. Нужно проверить выборку самых маленьких bbox, удалить или переразметить при необходимости; разработать стратегию для малых объектов (повышение разрешения, мульти-скейл, ROI-каскад). 


Сводная статистика по изображениям, где есть хотя бы один bbox:

| split | images_total | bboxes_total | bbox_per_image_mean | width_px_mean | height_px_mean |  area_px_05 | area_px_p50 |  area_px_p90 |
| :---- | -----------: | -----------: | ------------------: | ------------: | -------------: | ----------: | ----------: | -----------: |
| test  |        30007 |        41481 |            1.382377 |     82.255399 |      80.735249 |  741.305615 | 6176.994166 | 14009.920306 |
| train |         4086 |         6827 |            0.805045 |     95.589960 |      92.540647 |  857.285302 | 8065.228825 | 14522.247000 |
| val   |          706 |         1763 |            2.497167 |    101.683673 |      97.985454 | 2891.199626 | 9050.949807 | 17329.120111 |

| split | aspect_mean | aspect_q05 | aspect_q95 | center_x_mean | center_x_std | center_y_mean | center_y_std |
| :---- | ----------: | ---------: | ---------: | ------------: | -----------: | ------------: | -----------: |
| test  |    1.129182 |   0.453703 |   2.116882 |      0.510173 |     0.286799 |      0.503750 |     0.284406 |
| train |    1.139437 |   0.450683 |   2.366991 |      0.503067 |     0.300250 |      0.493794 |     0.280244 |
| val   |    1.161277 |   0.476004 |   2.333377 |      0.501427 |     0.196259 |      0.511063 |     0.249590 |

- **bbox_per_image_mean** - среднее число людей на кадр (плотность целей)
  В валидационной выборке оно выше, чем в тренировочной и тестовой, значит валидация может давать более оптимистичную картину по recall по сравнению с реальным потоком. Нужно проверить, нет ли в валидации перекоса по сценам
    
- **width_px_mean / height_px_mean, area_px_p05/p50/p90** - типичный размер цели в пикселях
  В валидационной выборке почти нет крайне маленьких целей, значит, модель может выглядеть хорошо на валидации, но деградировать в миссиях, где мелких целей больше. Нужно готовить модель к более мелким объектам через обучение и аугментации
    
- **aspect_mean/q05/q95** — соотношение сторон
  Боксы в среднем почти квадратные, но существуют более вытянутые по горизонтали, но квантили q05/q95 указывают на наличие вытянутых разметок. Перед обучением нужно проверить, выбросы ли это
    
- **center_x_mean / center_y_mean** - среднее положение объектов в кадре (в долях размеров кадра)
  Значение близки к 0.5, в среднем объекты распределены примерно симметрично по кадру
	
- **center_x_std / center_y_std** 
  Цели в валидационной выборке более собраны по позиции (ещё один сигнал перекоса сцен).  
    Действие: проверить, что разбиение делалось по миссиям/сценам без утечки и без случайного отбора “слишком удобных” кадров.


**Таргет**: bbox человека в формате YOLO  
$$
\langle class\_id, x, y, w, h\rangle,  
$$  
где $x,y$ — центр bbox, $w,h$ — ширина/высота, все величины нормированы в долях ширины/высоты изображения.

Корректные боксы на кадрах - это основа для построения эпизодов на продуктовом слое. Ошибка детектора FN увеличивает вероятность пропуска целого эпизода, значит ухудшает полноту по эпизодам, из-за чего падает полезность подсказок и смысл ML-режима мониторинга. Поэтому в данной задаче целевой приоритет в обучении - это **максимизация полноты** при контроле ложных тревог


Что нужно сделать перед обучением:

1. Вручную проверить выборку самых маленьких боксов и решить, оставляем, и тогда обучаемся под маленькие объекты, либо чистим, и тогда вводим минимальный порог площади/размера и пересохраняем лейблы).
    
2. Пересобрать валидационную выборку, чтобы она отражала наличие очень малых целей и пространственное распределение, близкое к test/миссиям.
    
3. Зафиксировать, чтобы конфиги для обучения и оценки использовали один и тот же словарь классов (class_id=0)

